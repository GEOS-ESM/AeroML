{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial to Create NNR\n",
    "This project requires that you source the setup_env.sh script before executing anything below.\n",
    "\n",
    "## Creating the Giant Spreadsheets\n",
    "\n",
    "First you need to make the dataset of AERONET-MODIS co-locations. <br>\n",
    "Run the run_create_giant.sh script. This calls the python code create_giant.py which will create two files in /nobackup/NNR/Training/061 - one each for Aqua and Terra:\n",
    "- giant_C061_10km_Aqua_v3.0_20211231.nc  \n",
    "- giant_C061_10km_Terra_v3.0_20211231.nc\n",
    "\n",
    "The script will run through the entire MODIS data record up until the end date indicated, in this case 2021-12-31. <br>\n",
    "You can modify the end date by editing the -E option inside the run_create_giant.sh script.\n",
    "\n",
    "This script will take several days to run.\n",
    "\n",
    "The script defaults are to use MODIS collection 061 and AERONET version 3.\n",
    "\n",
    "The script co-locates the data according to the following criteria:\n",
    "- MODIS observations are within 27.5 km of an AERONET site\n",
    "- AERONET observations are within 30 minutes of MODIS overpass\n",
    "\n",
    "### Description of what create_giant.py does:\n",
    "creat_giant.py relies on two pyobs libraries: mxd04.py and aeronet.py to read the MODIS and AERONET files\n",
    "\n",
    "Important caveat of aeronet.py is that the AOD values at 550, 660, 670, and 470 nm are angstrom interpolated from measurements at neighboring wavelengths. When these values are returned to create_giant.py, it does a check to see that AOD at 550 nm is greater than zero. It then filters out any observations that don't meet that criteria.\n",
    "\n",
    "The mxd04.py script reads in the MODIS granules, and is run with the only_good option set to True.\n",
    "This filters the observations according to the MODIS reported QA Flag. The only_good threshholds are different for each retrieval.\n",
    "- BAD, MARGINAL, GOOD, BEST = ( 0, 1, 2, 3 )\n",
    "- LAND: qa_flag == BEST \n",
    "- OCEAN: qa_flag  > BAD\n",
    "- DEEP: qa_flag > BAD\n",
    "\n",
    "After this data is passed back to create_giant.py, additional filters are applied.\n",
    "1. Cloud fraction < 0.7\n",
    "2. All reported TOA reflectance values > 0\n",
    "3. All reported surface reflectance values > 0\n",
    "4. OCEAN: glint angle > 40 <br>\n",
    "   LAND & DEEP: scattering angle < 170\n",
    "\n",
    "create_giant.py then does a co-location between the MODIS obs and the AERONET obs according to the criteria above.\n",
    "It calculates the mean, mode, and standard deviation of the respective co-located observations. \n",
    "\n",
    "There need to be atleast 2 AERONET obs and 5 MODIS obs to make a match.\n",
    "\n",
    "The create_giant.py script uses the header information from the text file giantHeader.txt to get the variable names and attributes to write to a netCDF file.  The giantHeader.txt file was generated from one of the giant spreadsheet files created by the MODIS team and so closely follows that format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Other Datasets\n",
    "\n",
    "Once the giant spreadsheet file is created, you need to sample other datasets at the MODIS-AERONET colocations.\n",
    "\n",
    "### To sample MERRA-2\n",
    "Run the run_sample_merra.sh script. This script calls the python code sample_merra.py that requires the name of the giant spreadsheet file as input. The names of the giant spreadsheet files are hardcoded in run_sample_merra.sh.\n",
    "\n",
    "sample_merra.py relies on the GIANT class to read the giant spreadsheet to get the lat,lon, and times of the co-locations, and calls the function 'sampleMERRA' attached to the GIANT class. \n",
    "sample_merra.py defines the name of the output .npz file from the giant spreadsheet filename.\n",
    "sample_merra.py assumes that you have two control files located in your directory:\n",
    "1. tavg1_2d_aer_Nx\n",
    "2. tavg1_2d_slv_Nx\n",
    "\n",
    "the sampleMERRA function will read the following variables from these two file collections\n",
    "- tavg1_2d_aer_Nx: 'TOTEXTTAU','DUEXTTAU','SSEXTTAU','BCEXTTAU','OCEXTTAU','SUEXTTAU'\n",
    "- tavg1_2d_slv_Nx: V10M, U10M\n",
    "\n",
    "It then calculates 10M wind speed, and the fraction AOD of the species. Note BC and OC are summed together to get fraction carbonaceous aerosol (acronym 'CC').\n",
    "\n",
    "The windspeed, V10M, U10M, and AOD fractions are written to the aforementioned npz file. \n",
    "\n",
    "### To sample MCD43C1\n",
    "First ensure that the MCD43C1 dataset is downloaded.  Run the run_download_mcd43c1.sh script. This script calls mcd43c_download.py.  This python code has an option called --root which sets the variable rootDir, this is the location of the dataset. Default is /nobackup/3/pcastell/MODIS/MCD43C1/061.\n",
    "The program loops through a date range given and will look in rootDir. If it doesn't find a file for a day it will download it from https://e4ftl01.cr.usgs.gov/MOTA/MCD43C1.061/\n",
    "\n",
    "Next, you have to sample the MCD43C1 data by running the run_sample_mcd43c1.sh script. This script calls the code sample_mcd43c1.py that requires the name of the giant spreadsheet as input. The names of the giant spreadsheet files are hardcoded in run_sample_mcd43c1.sh.\n",
    "\n",
    "sample_mcd43c1.py relies on the GIANT class to read the giant spreadsheet to get the lat, lon, and times of the co-location, and calls the function 'sampleMCD43C' attached to the giant class. Note that the way sample_mcd43c1.py is currently set up it implicitly assumes that you're using the detault rootDir above, but you could pass the sampleMCD43C function the optional variable \"inDir\" if the data is in another directory.  After sampling, the function writes the values to an npz file defined in sample_mcd43c1.py that's based on the giant spreadsheet filename.\n",
    "\n",
    "### To calculate Cox-Munk BRDF\n",
    "First ensure that the MERRA-2 wind speeds have been sampled above. Run the shell script run_sample_cxalbedo.sh. This script calls the code sample_cxalbedo.py, which requires the name of the giant spreadsheet as input.  The names of the giant spreadsheet files are hardcoded in run_sample_cxalbedo.sh.  \n",
    "\n",
    "sample_cxalbedo.py relies on the GIANT class to calculate the CX BRDF from the model sampled 10M wind speeds.  The function writes the values to an npz file defined in sample_cxalbedo.py that's based on the giant spreadsheet filename."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the NNR\n",
    "\n",
    "Once the giant spreadsheed and sampled MERRA-2 and other datasets are prepared, you can now train the neural network.\n",
    "This is done seperately for each MODIS retrieval algorithm with the following python programs:\n",
    "train_land.py\n",
    "train_deep.py\n",
    "train_ocean.py\n",
    "\n",
    "Within these scripts there are options for inputs, targets, and how to set up the neural network. These are explained in the comments of the python programs. They require that the MERRA-2 and other sampled npz files are located in the same directory as the giant file.\n",
    "\n",
    "Here are some things to note:\n",
    "1. the scripts can test different combinations of inputs when you set the 'combinations' variable to True. The Input_const variable list is used in the all the tested combinations. The code takes the Input_nnr list of variables and creates all possible combitions with the Input_const list.  If 'combinations' is set to False, it trains on the combined full list of Input_nnr and Input_const\n",
    "2. the script can implement training and testing in k-folds by setting the variables K to an integer. Otherwise, if set to none it will train on the balanced subset and test on the entire dataset. Balancing is done by making sure that no aerosol type makes up more than 35% of the total number of obs.\n",
    "3. The code intializes and 'ABC' class defined in the abc_c6.py program. The ABC classes have a default list of variables that it filters the observations by. These are hardcoded in the abc_c6.py program, and varies by the retrieval. This is the list of variables that it checks for valid values automatically\n",
    "\n",
    "\n",
    "- LAND: \n",
    "        qa == 3 \n",
    "        AERONET obs aTau470, 550, 660 > -0.01\n",
    "        MODIS retrieved mTau470, 550, 660, 2100 > -0.01\n",
    "        MODIS cloud fraction >=0 and < 0.70\n",
    "        MODIS scattering angle < 170.\n",
    "        MODIS obs reflectance mRef412, 440, 470, 550, 660, 870, 1200, 1600, 2100 > 0\n",
    "        MODIS reported surface reflectance mSre470, 660, 2100 > 0    \n",
    "- DEEP: \n",
    "        qa == 3\n",
    "        AERONET obs aTau470, 550, 660 > -0.01\n",
    "        MODIS retrieved mTau412, 470, 550, 660 > -0.01\n",
    "        MODIS cloud fraction >=0 and < 0.70\n",
    "        MODIS scattering angle < 170.\n",
    "        MODIS obs reflectance mRef412, 470, 660 > 0\n",
    "        MODIS reported surface reflectance mSre412, 470, 660 > 0\n",
    "- OCEAN:\n",
    "        qa > 0\n",
    "        AERONET obs aTau470, 550, 660, 870 > -0.01\n",
    "        MODIS retrieved mTau470, 550, 660, 870 > -0.01\n",
    "        MODIS cloud fraction >=0 and < 0.70\n",
    "        MODIS glint angle > 40\n",
    "        MODIS obs reflectance mRef470, 550, 660, 870, 1200, 1600, 2100 > 0\n",
    "        \n",
    "\n",
    "You can add additional variables to filter by with the 'aFilter' variable in train_X.py. Otherwise, 'aFilter' can be just set to None.\n",
    "\n",
    "The ABC classes also have an optional 'tymemax' variable that if set cuts off the MODIS-AERONET colocation data record at the date given.\n",
    "\n",
    "3. The next thing that the ABC classes do is remove outliers.  It's based on log-transformed AOD at 550 nm. First it calculates the difference between the MODIS retrieved and AERONET log(AOD550+0.01). It filters any observations where the difference is more than 3 standard deviations from the mean difference. The code does 3 iterations of this - recalculating the mean and standard deviation each time with the reduced dataset.\n",
    "4. Next step is to convert all observations angles to cos(angle)\n",
    "\n",
    "After the QA checks and data transformations, the code trains the neural network, and if testing is asked for in the train_X.py script, it will output diagnostic plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
